{
 "cells": [
  {
   "cell_type": "raw",
   "id": "8ea3ea92-ef73-4f9a-b257-aacc786cdb70",
   "metadata": {},
   "source": [
    "Stopwords adalah kata-kata umum yang sering muncul di dalam sebuah teks dan tidak membawa makna yang signifikan dalam pemrosesan \n",
    "teks atau analisis bahasa alami. Contohnya adalah \"the\", \"a\", \"an\", \"in\", \"on\", \"and\", \"of\", dan sebagainya. Oleh karena itu, \n",
    "dalam pemrosesan teks, stopwords sering kali dihapus atau diabaikan untuk meningkatkan efisiensi dan akurasi analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5f5ad71-505d-4136-bc80-1b7be66c4fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I’m amazed how often in practice, not only does a @huggingface NLP model solve your problem, but one of their public finetuned checkpoints, is good enough for the job.\\nBoth impressed, and a little disappointed how rarely I get to actually train a model that matters :('"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = \"\"\"I’m amazed how often in practice, not only does a @huggingface NLP model solve your problem, but one of their public finetuned checkpoints, is good enough for the job.\n",
    "Both impressed, and a little disappointed how rarely I get to actually train a model that matters :(\"\"\"\n",
    "\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "250f20fa-356b-4cca-a760-82ece0ae4063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Raqwan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# kayanya versi terbaru harus download dlu\n",
    "\n",
    "import nltk \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a334d70-9288-4d27-a0f9-6a4dd2d8bb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english') # mengambil kata kata dari kamus inggris\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21bf0322-95af-41a2-bc03-628d8517bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Fungsi set() pada baris tersebut mengubah list stop_words menjadi kumpulan set stop_words yang unik. \n",
    "Hal ini dilakukan untuk menghilangkan duplikat dalam stop_words. Pada umumnya, ketika menggunakan stop words, \n",
    "tidak diperlukan duplikasi, sehingga mengubahnya menjadi set akan membantu mengurangi jumlah kata yang perlu diproses oleh program, meningkatkan efisiensi dan kecepatan.\n",
    "'''\n",
    "\n",
    "stop_words = set(stop_words)\n",
    "tweet = tweet.lower().split() # split every character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51f494fd-d546-49ea-8665-80b81423edb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With stopwords : i’m amazed how often in practice, not only does a @huggingface nlp model solve your problem, but one of their public finetuned checkpoints, is good enough for the job. both impressed, and a little disappointed how rarely i get to actually train a model that matters :(\n",
      "\n",
      "Without : i’m amazed often practice, @huggingface nlp model solve problem, one public finetuned checkpoints, good enough job. impressed, little disappointed rarely get actually train model matters :( \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_no_stopwords = [word for word in tweet if word not in stop_words]\n",
    "\n",
    "print(f\"With stopwords : {' '.join(tweet)}\\n\")\n",
    "print(f\"Without : {' '.join(tweet_no_stopwords)} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
